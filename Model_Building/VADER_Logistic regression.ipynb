{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tweet</th>\n",
       "      <th>polarity</th>\n",
       "      <th>subjectivity</th>\n",
       "      <th>vader_neg</th>\n",
       "      <th>vader_neu</th>\n",
       "      <th>vader_pos</th>\n",
       "      <th>vader_compound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [tweet, polarity, subjectivity, vader_neg, vader_neu, vader_pos, vader_compound]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df = pd.read_excel(\"data.xls\")\n",
    "li = df[df.isnull().T.any()].index\n",
    "for i in li:\n",
    "    df.drop(index=i,axis = 1,inplace = True)\n",
    "df[df.isnull().T.any()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 1    3294\n",
       " 0    2936\n",
       "-1    1427\n",
       "Name: vd_new, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['vd_new']=5\n",
    "df.loc[df['vader_compound']==0,['vd_new']]=0\n",
    "df.loc[df['vader_compound']>0,['vd_new']]=1\n",
    "df.loc[df['vader_compound']<0,['vd_new']]=-1\n",
    "df['vd_new'].value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df['tweet']\n",
    "Y = df['vd_new']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1766    Video Dubai residents queue up to receive COVI...\n",
       "7267    This is MY better half and I m supposed to get...\n",
       "1430    Neither will we PfizerBioNTech has produced an...\n",
       "3551    uk Apart from the oxfordvaccine the Moderna Pf...\n",
       "2405    Are you counted as been vaccinated after the f...\n",
       "                              ...                        \n",
       "4063    The BMJ 23 patients have died in Norway shortl...\n",
       "1346    Joe Biden receives his first dose of Pfizer CO...\n",
       "3457    Laboratory tests have shown the PfizerBioNTech...\n",
       "7537    My hubby is fully vaccinated Thank you Science...\n",
       "3585    Anyone in Ireland or anywhere else thinking of...\n",
       "Name: tweet, Length: 6125, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<1532x200 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 13212 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "num_features = 200\n",
    "vect = CountVectorizer(max_features=num_features)\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_test_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn import metrics\n",
    "# instantiate a logistic regression model\n",
    "logreg = LogisticRegression(multi_class='multinomial', solver=\"lbfgs\", C=10, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 239 ms, sys: 8.87 ms, total: 248 ms\n",
      "Wall time: 259 ms\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linqiaoyi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, multi_class='multinomial', random_state=123)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time logreg.fit(X_train_dtm,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.6298955613577023\n",
      "Precision:0.6298955613577023\n",
      "Recall:0.6298955613577023\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.56      0.34      0.43       294\n",
      "           0       0.59      0.77      0.67       598\n",
      "           1       0.70      0.63      0.66       640\n",
      "\n",
      "    accuracy                           0.63      1532\n",
      "   macro avg       0.62      0.58      0.59      1532\n",
      "weighted avg       0.63      0.63      0.62      1532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "y_test_pred = logreg.predict(X_test_dtm)\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print(\"Accuracy:{}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Precision:{}\".format(precision_score(y_test, y_test_pred,average='micro')))\n",
    "print(\"Recall:{}\".format(recall_score(y_test, y_test_pred,average='micro')))\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "def custom_preprocessor(text):\n",
    "    '''\n",
    "    Make text lowercase, remove text in square brackets,remove links,remove special characters\n",
    "    and remove words containing numbers.\n",
    "    '''\n",
    "    text = text.lower()\n",
    "    text = re.sub('\\[.*?\\]', '', text)\n",
    "    text = re.sub(\"\\\\W\",\" \",text) # remove special chars\n",
    "    text = re.sub('https?://\\S+|www\\.\\S+', '', text)\n",
    "    text = re.sub('<.*?>+', '', text)\n",
    "    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n",
    "    text = re.sub('\\n', '', text)\n",
    "    text = re.sub('\\w*\\d\\w*', '', text)\n",
    "    words = word_tokenize(text)\n",
    "    words = [i for i in words if i not in stopwords.words()]\n",
    "    text = ' '.join(words)\n",
    "    \n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1766    video dubai residents queue receive vaccinatio...\n",
       "7267    better half supposed get first pfizerbiontech ...\n",
       "1430    neither pfizerbiontech produced experimental m...\n",
       "3551    uk apart oxfordvaccine moderna pfizerbiontech ...\n",
       "2405                     counted vaccinated first jab sec\n",
       "                              ...                        \n",
       "4063    bmj patients died norway shortly receiving pfi...\n",
       "1346    joe biden receives first dose pfizer covid vac...\n",
       "3457    laboratory tests shown pfizerbiontech vaccine ...\n",
       "7537    hubby fully vaccinated thank science pfizerbio...\n",
       "3585    anyone ireland anywhere else thinking receivin...\n",
       "Name: tweet_clean, Length: 6125, dtype: object"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['tweet_clean']=df['tweet'].apply(custom_preprocessor)\n",
    "X = df['tweet_clean']\n",
    "Y = df['vd_new']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.2, random_state=123)\n",
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<6125x39898 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 100109 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vect = CountVectorizer(ngram_range=(1,2))\n",
    "X_train_dtm = vect.fit_transform(X_train)\n",
    "X_test_dtm = vect.transform(X_test)\n",
    "X_train_dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.88 s, sys: 52.1 ms, total: 2.93 s\n",
      "Wall time: 1.58 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/linqiaoyi/opt/anaconda3/lib/python3.8/site-packages/sklearn/linear_model/_logistic.py:762: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "logreg = LogisticRegression()\n",
    "logreg.fit(X_train_dtm,y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.7663185378590078\n",
      "Precision:0.7663185378590078\n",
      "Recall:0.7663185378590078\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "          -1       0.78      0.45      0.57       294\n",
      "           0       0.71      0.92      0.80       598\n",
      "           1       0.84      0.77      0.80       640\n",
      "\n",
      "    accuracy                           0.77      1532\n",
      "   macro avg       0.78      0.71      0.72      1532\n",
      "weighted avg       0.78      0.77      0.76      1532\n",
      "\n"
     ]
    }
   ],
   "source": [
    "y_test_pred = logreg.predict(X_test_dtm)\n",
    "print(\"Accuracy:{}\".format(accuracy_score(y_test, y_test_pred)))\n",
    "print(\"Precision:{}\".format(precision_score(y_test, y_test_pred,average='micro')))\n",
    "print(\"Recall:{}\".format(recall_score(y_test, y_test_pred,average='micro')))\n",
    "print(classification_report(y_test,y_test_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2       Facts are immutable, Senator, even when you're...\n",
       "3       Explain to me again why we need a vaccine @Bor...\n",
       "4       Does anyone have any useful advice/guidance fo...\n",
       "5       it is a bit sad to claim the fame for success ...\n",
       "6       There have not been many bright days in 2020 b...\n",
       "                              ...                        \n",
       "3101    #PublicHealth #COVID19 #Modernavaccine #Modern...\n",
       "3102    @crashoverrideee #COVID19 Vaccine Update for #...\n",
       "3103    Dr Fun's I Feel Good - My effort at a PSA, ple...\n",
       "3104    @Writer_DG I got dose #2 Friday. Have to admit...\n",
       "3105    Feeling very privileged to have had my first c...\n",
       "Name: text, Length: 247, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "df1 = pd.read_csv('Finished_vaccination_tweets_手动标记.csv',encoding='ISO-8859-1')\n",
    "df1 = df1[(df1['code-attitude'] == '0') | (df1['code-attitude'] == '1') | (df1['code-attitude'] == '-1')]\n",
    "df1['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:0.6396761133603239\n"
     ]
    }
   ],
   "source": [
    "df1['text'] = pd.DataFrame(df1['text'].astype(str))\n",
    "df1['text_clean']=df1['text'].apply(custom_preprocessor)\n",
    "t = vect.transform(df1['text_clean'])\n",
    "y_test_pred = logreg.predict(t)\n",
    "df1['code-attitude'] = pd.DataFrame(df1['code-attitude'].astype(int))\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
    "print(\"Accuracy:{}\".format(accuracy_score(df1['code-attitude'], y_test_pred)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
